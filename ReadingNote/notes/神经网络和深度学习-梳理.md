- 第一章
    - 感知器
        - 一种**接收多个**二进制数据进行计算后**输出一个**二进制数据的计算单元
    - Sigmoid神经元(S神经元)
        - 一种接收多个0~1范围数据进行计算后输出一个0~1范围数据的计算单元
    - 神经网络
        - 由输入层，输出层和多个隐藏层，组成的网络，每层由多个神经元组成
    - 梯度下降
        - 代价函数（二次代价函数）
        - 梯度下降原理
        - 二次代价函数+梯度下降的代码实现 MNIST
- 第二章
    - 反向传播算法原理
        - 反向传播4个基本方程及其证明
    - 反向传播算法的代码实现
- 第三章
    - 训练中发现的问题及其解决方案
        - 反常识的学习速度问题
            - 解决方案：更换代价函数，使用交叉熵代价函数替换二次代价函数
                - 交叉熵代价函数原理
                    - 解释，交叉熵代价函数为何比二次代价函数更优的原因
        - 过度拟合问题
            - 解决方案：权重衰减（L2规范化），在代价函数中加入额外项
                - 解释，规范化解决过度拟合问题的原理
                - 其他规范化方法
                    - L1规范化：在代价函数上加上一个权重绝对值的和
                    - 弃权：临时性地随机删除网络中的一半的隐藏神经元，再辅以一些平均或者投票的方式来选择输出结果
                    - 人为扩展训练数据：对已有训练数据做小幅变动后加入训练（MNIST中为按照固定角度旋转用于训练的手写字，以扩充训练集）
        - 权重初始化值对训练结果的影响
            - 优化权重初始化值：可以提升训练速度和性能
        - 使用代码实现权重初始化的优化与规范化
        - 训练用超参数的选择策略
            - 常用超参数包括
                - 训练速率
                - 规范化参数
                - 随机梯度下降的采样数
        - 其他优化训练的方法
            - Hessian技术
            - 基于momentum的梯度下降
            - 使用其他类型的神经元，替换Sigmoid神经元
                - tanh 神经元：Sigmoid神经元的按比例变化版本，其输出值范围从 0~1 变为 -1~1
                - ReLU: 修正线性神经元（rectifiedlinearneuron）或者修正线性单元（rectified linearunit）
- 第四章
    - 神经网络普遍性定理的理解